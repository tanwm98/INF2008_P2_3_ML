# -*- coding: utf-8 -*-
"""Untitled0.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1741o1vrKo-mQfoHSLhwN2R0lHA3AkiJn
"""

# Commented out IPython magic to ensure Python compatibility.
import warnings
warnings.filterwarnings('ignore')

import sklearn
import pandas as pd
import numpy as np
import matplotlib
import platform
import seaborn as sns
import matplotlib.pyplot as plt
import re
from sklearn import datasets
from sklearn import metrics
from matplotlib import pyplot as plt
import seaborn as sns
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
from sklearn import ensemble, tree, linear_model
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.utils import shuffle
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.dummy import DummyRegressor


# %matplotlib inline

message="        Versions        "
print("*"*len(message))
print(message)
print("*"*len(message))
print("Scikit-learn version={}".format(sklearn.__version__))
print("Numpy version={}".format(np.__version__))
print("Pandas version={}".format(pd.__version__))
print("Matplotlib version={}".format(matplotlib.__version__))
print("Python version={}".format(platform.python_version()))

df = pd.read_csv("dataset/gold_data.csv")
df[:5]

# Delete the 0th and 1st entries (drop the first two rows)
df = df.iloc[2:].reset_index(drop=True)

# Drop Price (Date in dataset)
df.drop(columns=['Price'], inplace=True)

# Save or view the modified dataset
# Replace 'modified_dataset.csv' with your desired output path
df.to_csv('modified_dataset.csv', index=False)

df[:5]

df.info()

correlation = df.corr()
plt.figure(figsize=(14, 14))
heatmap = sns.heatmap(correlation, annot=True, linewidths=0, vmin=-1, cmap="RdBu_r")

df_result = df.loc[:,['Next_Day_Change']]

df.drop(columns=['Next_Day_Change'], inplace=True)

df_data = df.loc[:,df.columns.tolist()]


df_data1, df_data2, df_result1, df_result2 = train_test_split(df_data, df_result, test_size = 0.25)
df_result1 = np.ravel(df_result1)

regressor = DummyRegressor()
regressor.fit(df_data1, df_result1)
df_predict = regressor.predict(df_data2)
r2_dummy = metrics.r2_score(df_result2, df_predict)
evs_dummy = metrics.explained_variance_score(df_result2, df_predict)
print("R-Squared Value: " + str(r2_dummy))
print("Explained Variance Score: " + str(evs_dummy))


regressor = LinearRegression()
regressor.fit(df_data1, df_result1)

df_predict = regressor.predict(df_data1)
r2_lr1 = metrics.r2_score(df_result1, df_predict)
evs_lr1 = metrics.explained_variance_score(df_result1, df_predict)
print("R-Squared Value: " + str(r2_lr1))
print("Explained Variance Score: " + str(evs_lr1))

df_predict = regressor.predict(df_data2)
r2_lr2 = metrics.r2_score(df_result2, df_predict)
evs_lr2 = metrics.explained_variance_score(df_result2, df_predict)
print("R-Squared Value: " + str(r2_lr2))
print("Explained Variance Score: " + str(evs_lr2))

# Training set metrics
train_pred = regressor.predict(df_data1)
train_mae = mean_absolute_error(df_result1, train_pred)
train_rmse = np.sqrt(mean_squared_error(df_result1, train_pred))
train_r2 = r2_score(df_result1, train_pred)

# Test set metrics
test_pred = regressor.predict(df_data2)
test_mae = mean_absolute_error(df_result2, test_pred)
test_rmse = np.sqrt(mean_squared_error(df_result2, test_pred))
test_r2 = r2_score(df_result2, test_pred)

print("\nLinear Regression Performance Metrics:")
print("\nTraining Set Metrics:")
print(f"Mean Absolute Error (MAE): {train_mae:.4f}")
print(f"Root Mean Squared Error (RMSE): {train_rmse:.4f}")
print(f"R-squared Score: {train_r2:.4f}")

print("\nTest Set Metrics:")
print(f"Mean Absolute Error (MAE): {test_mae:.4f}")
print(f"Root Mean Squared Error (RMSE): {test_rmse:.4f}")
print(f"R-squared Score: {test_r2:.4f}")
