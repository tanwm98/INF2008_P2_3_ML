# -*- coding: utf-8 -*-
"""Midas'Algorithm.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1741o1vrKo-mQfoHSLhwN2R0lHA3AkiJn
"""

# Commented out IPython magic to ensure Python compatibility.
import warnings
warnings.filterwarnings('ignore')

import sklearn
import pandas as pd
import numpy as np
import matplotlib
import platform
import seaborn as sns
import matplotlib.pyplot as plt
import re
from sklearn import datasets
from sklearn import metrics
from matplotlib import pyplot as plt
import seaborn as sns
from sklearn.metrics import confusion_matrix, r2_score, mean_squared_error
from sklearn import ensemble, tree, linear_model
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.utils import shuffle

# %matplotlib inline

message="        Versions        "
print("*"*len(message))
print(message)
print("*"*len(message))
print("Scikit-learn version={}".format(sklearn.__version__))
print("Numpy version={}".format(np.__version__))
print("Pandas version={}".format(pd.__version__))
print("Matplotlib version={}".format(matplotlib.__version__))
print("Python version={}".format(platform.python_version()))

df = pd.read_csv("gold_details.csv")
df[:5]

# Delete the 0th and 1st entries (drop the first two rows)
df = df.iloc[2:].reset_index(drop=True)

# Drop Price (Date in dataset)
df.drop(columns=['Date'], inplace=True)

# Save or view the modified dataset
# Replace 'modified_dataset.csv' with your desired output path
df.to_csv('modified_dataset.csv', index=False)

df[:5]

df.info()

correlation = df.corr()
plt.figure(figsize=(14, 14))
heatmap = sns.heatmap(correlation, annot=True, linewidths=0, vmin=-1, cmap="RdBu_r")

df_result = df.loc[:,['Gold_Next_Day_Close']]

df.drop(columns=['Gold_Next_Day_Close'], inplace=True)

df_data = df.loc[:,df.columns.tolist()]

from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
df_data_train, df_data_test, df_result_train, df_result_test = train_test_split(df_data, df_result, test_size = 0.25)
df_result_train = np.ravel(df_result_train)

from sklearn.dummy import DummyRegressor
regressor = DummyRegressor()
regressor.fit(df_data_train, df_result_train)
df_predict = regressor.predict(df_data_test)
r2_dummy = metrics.r2_score(df_result_test, df_predict)
evs_dummy = metrics.explained_variance_score(df_result_test, df_predict)
print("R-Squared Value: " + str(r2_dummy))
print("Explained Variance Score: " + str(evs_dummy))

from sklearn.linear_model import LinearRegression
regressor = LinearRegression()
regressor.fit(df_data_train, df_result_train)

from sklearn.linear_model import ElasticNet
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, explained_variance_score

# Initialize the ElasticNet regressor
elasticnet = ElasticNet()

# Fit the model with your training data (assuming you have df_data_train and df_result_train)
elasticnet.fit(df_data_train, df_result_train)

# Make predictions
df_predict = elasticnet.predict(df_data_test)

# Calculate R-squared value
r2_lr2 = r2_score(df_result_test, df_predict)

# Calculate Explained Variance Score
evs_lr2 = explained_variance_score(df_result_test, df_predict)

# Calculate Mean Absolute Error
mae = mean_absolute_error(df_result_test, df_predict)

# Calculate Mean Squared Error
mse = mean_squared_error(df_result_test, df_predict)

# Print the metrics
print("R-Squared Value: " + str(r2_lr2))
print("Explained Variance Score: " + str(evs_lr2))
print("Mean Absolute Error: " + str(mae))
print("Mean Squared Error: " + str(mse))

from sklearn.linear_model import Lasso
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, explained_variance_score

# Initialize the Lasso regressor
lasso = Lasso(alpha=0.1)  # You can adjust the alpha value for regularization

# Fit the Lasso model with training data
lasso.fit(df_data_train, df_result_train)

# Make predictions with the Lasso model
df_predict = lasso.predict(df_data_test)

# Ensure df_result_test and df_predict are NumPy arrays for element-wise operations
df_result_test_array = np.array(df_result_test).flatten()
df_predict_array = np.array(df_predict).flatten()

# Define a tolerance for regression accuracy
tolerance = 0.01  # Predictions within 10% of the true value are considered "accurate"

# Calculate custom regression accuracy
correct_predictions = np.abs(df_predict_array - df_result_test_array) <= tolerance * np.abs(df_result_test_array)
accuracy = np.mean(correct_predictions) * 100

# Calculate regression metrics
r2_lr2 = r2_score(df_result_test, df_predict)
evs_lr2 = explained_variance_score(df_result_test, df_predict)
mae = mean_absolute_error(df_result_test, df_predict)
mse = mean_squared_error(df_result_test, df_predict)

# Print regression metrics
print("R-Squared Value: {:.5f}".format(r2_lr2))
print("Explained Variance Score: {:.5f}".format(evs_lr2))
print("Mean Absolute Error: {:.2f}".format(mae))
print("Mean Squared Error: {:.2f}".format(mse))
print("Regression Accuracy (within {:.1f}% tolerance): {:.2f}%".format(tolerance * 100, accuracy))

from sklearn.svm import SVR
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, explained_variance_score

# Initialize the SVR with a linear kernel
svr = SVR(kernel='linear')  # Linear kernel for SVR

# Fit the model with your training data (assuming you have df_data_train and df_result_train)
svr.fit(df_data_train, df_result_train)

# Make predictions
df_predict = svr.predict(df_data_test)

# Calculate R-squared value
r2_lr2 = r2_score(df_result_test, df_predict)

# Calculate Explained Variance Score
evs_lr2 = explained_variance_score(df_result_test, df_predict)

# Calculate Mean Absolute Error
mae = mean_absolute_error(df_result_test, df_predict)

# Calculate Mean Squared Error
mse = mean_squared_error(df_result_test, df_predict)

# Print the metrics
print("R-Squared Value: " + str(r2_lr2))
print("Explained Variance Score: " + str(evs_lr2))
print("Mean Absolute Error: " + str(mae))
print("Mean Squared Error: " + str(mse))

from sklearn.linear_model import Ridge
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, explained_variance_score

# Initialize the Ridge regressor with an optional alpha value
ridge = Ridge(alpha=1.0)  # You can adjust alpha for regularization strength

# Fit the model with your training data (assuming you have df_data_train and df_result_train)
ridge.fit(df_data_train, df_result_train)

# Make predictions
df_predict = ridge.predict(df_data_test)

# Calculate R-squared value
r2_lr2 = r2_score(df_result_test, df_predict)

# Calculate Explained Variance Score
evs_lr2 = explained_variance_score(df_result_test, df_predict)

# Calculate Mean Absolute Error
mae = mean_absolute_error(df_result_test, df_predict)

# Calculate Mean Squared Error
mse = mean_squared_error(df_result_test, df_predict)

# Print the metrics
print("R-Squared Value: " + str(r2_lr2))
print("Explained Variance Score: " + str(evs_lr2))
print("Mean Absolute Error: " + str(mae))
print("Mean Squared Error: " + str(mse))